{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLUCLr2dsyWQ"
   },
   "source": [
    "<b><h1>DNS Water Torture σε Recursive DNS Servers</h1></b>\n",
    "\n",
    "<p align=\"justify\">Στην άσκηση αυτή, θα αναπτύξετε ένα μηχανισμό αντιμετώπισης επιθέσεων <i>DNS Water Torture</i> σε <i>Recursive DNS Servers</i> (δίνεται <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/2020/lab7/Lab7_theory.pdf\">υποστηρικτικό υλικό</a> για την άσκηση). Ουσιαστικά, το πρόβλημα αυτό είναι ένα πρόβλημα text classification που έγγυται στο διαχωρισμό ονομάτων DNS που είναι <i>έγκυρα (valid)</i> και <i>άκυρα (invalid)</i>. </p>\n",
    "\n",
    "<p align=\"justify\">Με τη βοήθεια του αλγορίθμου Naive Bayes Classifier, θα διαχωρίσετε τα prefixes των <i>ονομάτων DNS</i> σε <i>έγκυρα</i> και <i>άκυρα</i>. Στην άσκηση αυτή, ως <i>prefix</i> ορίζουμε το <i>πρώτο label</i> ενός <i>ονόματος DNS</i>. Για παράδειγμα, το prefix του ονόματος <a href=\"https://www.ntua.gr/el/\">www.ntua.gr</a> είναι το <i>www</i>, ενώ το prefix του ονόματος <a href=\"dolly.netmode.ece.ntua.gr\">dolly.netmode.ece.ntua.gr</a> είναι το <i>dolly</i>.</p>\n",
    "\n",
    "<p align=\"justify\">Ο αλγόριθμος θα εκπαιδευτεί με <u>έγκυρα ονόματα</u> (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/2020/lab7/valid_training.txt\">valid_training.txt</a>) και άκυρα ονόματα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/2020/lab7/invalid_training.txt\">invalid_training</a>.txt). Η δοκιμή του θα γίνει στο <u>test set</u>, που περιλαμβάνει, επίσης, έγκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/2020/lab7/valid_test.txt\">valid_test.txt</a>) και άκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/2020/lab7/invalid_test.txt\">invalid_test.txt</a>) ονόμάτα.</p>\n",
    "\n",
    "<p align=\"justify\">Να απαντήσετε στις ακόλουθες ερωτήσεις:</p>\n",
    "<ul>\n",
    "<li> 1) Ποια είναι η παραδοχή του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;</li>\n",
    "<li> 2) Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>.</li>\n",
    "<li> 3) Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/2020/lab7/valid_training.txt\">valid_training.txt</a> και <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/2020/lab7/invalid_training.txt\">invalid_training.txt</a>. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων.</li>\n",
    "<li> 4) Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;</li>\n",
    "<li> 5) Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο <i>test set</i>. Ποιο είναι το μέγεθος του <i>training set</i>; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;</li>\n",
    "<li> 6)Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: <i>problematic_valid.txt</i> και <i>problematic_invalid.txt</i>. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (<a href=\"https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf\">https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf</a>);</li>\n",
    "<li> 7) Μελετώντας τη συνάρτηση <i>find_prob()</i>, θα δείτε πως λείπουν οι πιθανότητες <i>prior</i> από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις <i>prior</i> πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (<i>valid</i>, <i>invalid</i>) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;</li>\n",
    "<li> 8) Μπορείτε να προτείνετε κάποιο επιπρόσθετο <i>feature</i> για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)</li>\n",
    "</ul>\n",
    "\n",
    "<p align=\"justify\"><b>Πηγές Δεδομένων</b></p>\n",
    "<ul>\n",
    "<li>Valid ονόματα: <a href=\"https://www.kaggle.com/cheedcheed/top1m\">https://www.kaggle.com/cheedcheed/top1m</a> (πολλά από τα κορυφαία σε επισκεψιμότητα site)</li>\n",
    "<li>Invalid ονόματα: Παράχθηκαν με το πρόγραμμα <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/2020/lab7/generator.py\">generator.py</a> που θα βρείτε μαζί με τα υπόλοιπα αρχεία της άσκησης.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Απαντήσεις__\n",
    "\n",
    "__1)__  H παραδοχή του αλγορίθμου Naive Bayes είναι πως θεωρεί Conditional Independence. Αυτό σημαίνει πως για ένα Χ=<Χ1,Χ2> μια δεσμευμένη πιθανότητα της μορφής P(X|Y) = P(X1,X2|Y) = P(X1|X2,Y)*P(X2|Y) = P(X1|Y)*P(X2|Y), δηλαδή τα χαρακτηριστικά ενός δείγματος είναι ανεξάρτητα μεταξύ τους δοσμένης μιας κλάσης. \n",
    "       Αυτή η παραδοχή απλοποιεί πάρα πολύ την κατάσταση, καθώς μειώνονται πάρα πολύ ο αριθμός των παραμέτρων που πρέπει να εκτιμήσουμε όταν μοντελοποιούμε μια πιθανότητα της μορφής \n",
    "       \n",
    "__2)__  Ο αλγόριθμος Naive Bayes βασίζεται στο κανόνα του Bayes κατά κύριο ρόλο και στην ανεξαρτησία των χαρακτηριστικών μεταξύ τους. Επομένως, έχοντας ως στόχο την εκμάθηση της πιθανότητας P(Y|X) όπου Χ = <Χ1,Χ2,..ΧΝ> ο αλγόριθμος θεωρεί πως κάθε Xi είναι ανεξάρτιτο από τα άλλα χαρακτηριστικά δεδομένου μιας κλάσης Y.\n",
    "\n",
    "Eπομένως καταλήγουμε στην εξής σχέση P(X1,...Xn|Y) = Product_1_to_n(P(Xi|Y)) . θα θεωρήσουμε πως τα Y είναι διακριτές τιμές ενώ τα Χ είτε διακριτές είτε πραγματικές. Στόχος του αλγορίθμου είναι να εκπαιδεύσει ένα classifier που θα εξάγει την πιθανότητα P(Y=yk|X1,...Xn). Η συγκεκριμένη ανισότητα ισούται με την παρακάτω έκφραση:\n",
    "\n",
    "  <img src=\"eq1.png\" /> <center>ή</center> <img src=\"eq2.png\" />\n",
    "  \n",
    "Ουσιαστικά η τελευταία εξίσωση χρησιμοποιείται για τον υπολογισμό της συγκεκριμένης πιθανότητας όταν έρχεται ένα νεό instance. Συνήθως μας ενδιαφέρει η κλάση με την υψηλότερη τέτοια πιθανότητα επομένως ταξινομούμε το δείγμα με τον παρακάτω τρόπο.\n",
    "\n",
    "  <img src=\"eq3.png\" />\n",
    "  \n",
    "Το οποίο απλοποιείται στην παρακάτω μορφή καθώς ο παρανομαστής είναι ίδιος σε όλα και λειτουργεί ως κανονικοποιήση για να αθροίζουν όλα σε 1 όπως επιβάλλεται σε πιθανότητες.\n",
    "\n",
    "   <img src=\"eq4.png\" />\n",
    "   \n",
    "Στη συνέχεια θα αναλύσουμε τον τρόπο που μαθαίνονται οι παραπάνω πιθανότητες. Γενικά χρησιμοποιείται η μέθοδος Maximum Likelihood Estimation που συνεπάγεται εύρεση σχετικής συχνότητας(υπάρχει και ο MAP estimator αλλά στην συγκεκριμένη  άσκηση δε χρησιμοποιείται). Επομένως υπολογίζουμε τις prior πιθανότητες  με τον εξής τύπο:\n",
    "\n",
    "P(Y=yk) = #of_yk / total_training_examples\n",
    "\n",
    "Eνώ για το κάθε χαρακτηριστικό, βλέπουμε πόσες φορές η τιμή του, συνυπάρχει με την κλάση yk. Αυτοί οι παράμετροι συνοψίζονται στον παρακάτω τύπο:\n",
    "\n",
    "  <img src=\"eq6.png\" />\n",
    "\n",
    "\n",
    "__3)__ Σχολιασμός των 2 αρχείων valid - invalid training.txt\n",
    "\n",
    "Μια εμφανής διαφορά είναι πως το αρχέιο invalid_training έχει στην πλειοψηφία των δεδομένων του αριθμούς σε κάθε prefix, ενώ κάποια έχουν πολύ μεγάλο length. Επίσης, δεν περιλαμβάνουν κανονικές λέξεις που χρησιμοποιούμε αλλά τελείως random.\n",
    "\n",
    "Από την άλλη το valid training έχει πολύ λιγότερους αριθμούς στα prefixes του, συνήθως δεν έχει καθόλου αλλά και αν έχει είναι μικρό το length των αριθμών και συνήθως βρίσκονται στο τέλος του prefix και όχι διάσπαρτα, όπως στο invalid. Επίσης, παρατηρούμε πως έχουμε και λέξεις-εκφράσεις, όπως\"shop\",\"service\",\"guidetojapanese\", \"translationnations\" τις οποίες τις γνωρίζουμε και δεν είναι τυχαίες. Τέλος, τα prefix στο συγκεκριμένο αρχείο έχουν πολύ μικρότερο length γενικά.\n",
    "\n",
    "Συνοπτικά, μπορούμε να ορίσουμε σα βασικές διαφορές το μήκος του prefix , το πλήθος των αριθμών ή της μέγιστης ακολουθίας αριθμών.\n",
    "\n",
    "__4)__ Ποια είναι η επιλογή των features του αλγορίθμου της άσκησης.\n",
    "\n",
    "    1)total_length -> Το συνολικό μήκος του κάθε prefix π.χ. www -> len(www) = 3\n",
    "    \n",
    "    2)total_digits -> Το σύνολο των αριθμών μέσα σε ένα prefix δηλαδή w1w321w -> 4\n",
    "    \n",
    "    3)max_numeric_sequence -> Η μέγιστη ακολουθία αριθμών π.χ. αν έχουμε  w1w321w ->3\n",
    "    \n",
    "    4)total_consonants -> O συνολικός αριθμός σύμφωνα, δηλαδή b1b321z = 3\n",
    "    \n",
    "    5)max_consonants_sequence -> Η μεγαλύτερη ακολουθία συμφώνων , π.χ. bc2z -> 2 \n",
    "    \n",
    "    6)total_vowels - > Ο συνολικός αριθμός φωνηέντων , π.χ. ae32a -> 3\n",
    "    \n",
    "    7)max_vowels_sequence ->  Η μεγαλύτερη ακολουθία φωνηέντων,  π.χ. ae32a -> 2\n",
    "\n",
    "__5)__ Σχολιασμός αποτελεσμάτων - εκπαίδευσης - χρόνου\n",
    "\n",
    "\n",
    "Training time:  21.725454092025757\n",
    "\n",
    "Ο αριθμός των δειγμάτων ήταν 1400000 (700κ + 700κ από τα invalid και valid training.txt)\n",
    "\n",
    "\n",
    "Valid names misclassified as invalid - Ratio:  1.9172947402180884\n",
    "\n",
    "Invalid names misclassified as valid - Ratio:  1.2655821677971868\n",
    "\n",
    "Παρατηρούμε πως η εκπαίδευση έγινε σχετικά γρήγορα για τον αριθμό δειγμάτων που έχουμε. Επίσης ο ρυθμός λάθους σε valid ή invalid classifier είναι περίπου 1 με 2%. Το θετικό που αναγνωρίζουμε τα invalid με τέτοια επιτυχία είναι πως μπορούμε να πετύχουμε το server μας να αποφεύγει DΝS water torture επιθέσεις. Ωστόσο καμιά φορά μπορεί να αποτύχουμε στην εξυπηρέτηση DNS που είναι valid.\n",
    "\n",
    "__6)__ Problematic files\n",
    "\n",
    "To πρόβλημα είναi πως τα problematic prefixes είχαν ορισμένες δομές, οι οποίες δε μαθεύτηκαν ποτέ από τον ταξινομητή γιατί δεν υπήρχαν στο training set. Για παράδειγμα, αν στο total length έχουμε 40 διαφορετικές τιμές μέσα από το training set , τότε στο test set αν έχουμε μια διαφορετική τιμή θα υπάρχει πρόβλημα. Για αυτό το λόγο θέτουμε την πιθανότητα ίση με 0 στο try except. \n",
    "\n",
    "To παραπάνω πρόβλημα συμβαίνει καθώς ορίσαμε ανεξαρτησία χαρακτηριστικών και επομένως αν μια από τις πιθανότητες αυτές είναι 0, τότε μηδενίζει όλη η παράσταση.\n",
    "\n",
    "Το πρόβλημα θα μπορούσε να λυθεί αν προσθέσουμε μια smoothing παράμετρο , δηλαδή μια τιμή πολύ πολύ μικρή για τις πιθανότητες που δεν έχει συναντήσει ώστε να μη μηδενίζει όλη η παράσταση κάθε φορά που συναντάει νέες τιμές.\n",
    "\n",
    " <img src=\"eq5.png\" /> , όπου l είναι η smoothing παράμετρος.\n",
    "\n",
    "__7)__\n",
    "\n",
    "H παραδοχή που κάναμε για τις prior πιθανότητες είναι ότι τις ορίσαμε ισοπίθανες. Αυτό ειναι λογικό, καθώς και τα valid και τα invalid prefixes στο training set είχαν τον ίδιο αριθμό δειγμάτων (700κ και 700κ) επομένως \n",
    "\n",
    "len(valid_training)/total = len(invalid_training)/total = 1/2 ,όπου total = 1,4 εκ.\n",
    "\n",
    "Ένας άλλος τρόπος επιλογής θα ήταν να τις εκτιμήσουμε από την αρχή από το training set, δηλαδή να δούμε συνολικά τον αριθμό των δειγμάτων εκπαίδευσης και μετά ξεχωριστά της κάθε κλάσεις και να κάνουμε την εξής πράξη:\n",
    "\n",
    "number_in_class / total_training_examples και αυτό μπορεί να μας δώσει την Prior πιθανότητα, αν δεν ορίσουμε πως είναι ισοπίθανες.\n",
    "\n",
    "__8)__\n",
    "\n",
    "Ένα επιπλέον χαρακτηριστικό που θα μπορούσε να βοηθήσει είναι η ύπαρξη μιας λέξης μέσα στο prefix. Είδαμε πως στα valid περιέχονται πολλές λέξεις που καταλαβαίνει ο άνθρωπος. Επομένως θα μπορούσαμε να κάνουμε αναζήτηση από κάποιο λεξικό και να δούμε πόσες λέξεις έχει ενα prefix. Ωστόσο, αυτό θα ανέβαζε την πολυπλοκότητα του χρόνου εκτέλεσης.\n",
    "\n",
    "Ένα άλλο χαρακτηριστικό θα μπορούσε, που δεν απαιτεί τόσο μεγάλη πολυπλοκότητα θα ήταν να μετράμε τις ακολουθίες αριθμών στην αρχή του Prefix, καθώς είδαμε πως τα valid prefix συνήθως ξεκινάνε με γράμμα και όχι αριθμό.\n",
    "\n",
    "Τέλος, μια ακόμα πρόταση θα μπορούσε να είναι ο συνολικός αριθμός ή και συνεχόμενη ακολουθία, χαρακτήρων τύπου, \"-\",\"#\",\"!\",\"$\",\"@\" κ.ο.κ. που δεν ανήκουν σε γράμμα ή αριθμό."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_plJQ1Z2i5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time took:  21.725454092025757\n",
      "Number of training examples valid - invalid and sum:  700000 700000 1400000\n",
      "Valid names misclassified as invalid - Ratio:  1.9172947402180884\n",
      "Invalid names misclassified as valid - Ratio:  1.2655821677971868\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "problematic1 = open(\"problematic_valid.txt\", \"w\")\n",
    "problematic2 = open(\"problematic_invalid.txt\", \"w\")\n",
    "\n",
    "def load_file(file_name):\n",
    "    fd = open(file_name, \"r\")\n",
    "    my_set = set()\n",
    "    for prefix in fd:\n",
    "        prefix = prefix.rstrip()\n",
    "        my_set.add(prefix)\n",
    "    return my_set\n",
    "\n",
    "def calculate_probabilities(dataset):\n",
    "    stats = dict()\n",
    "    for index in range(0, 7):\n",
    "        stats[index] = dict()\n",
    "    for prefix in dataset:\n",
    "        features = handle_name(prefix)\n",
    "        for index in range(0, 7):\n",
    "            try:\n",
    "                stats[index][features[index]] += 1\n",
    "            except:\n",
    "                stats[index][features[index]] = 1\n",
    "\n",
    "    dataset_size = len(dataset)    \n",
    "    for index in range(0, 7):\n",
    "        for key in stats[index]:\n",
    "            stats[index][key] /= dataset_size\n",
    "    return stats\n",
    "\n",
    "def handle_name(prefix):\n",
    "    total_length = len(prefix)\n",
    "    total_digits, max_numeric_sequence = numeric(prefix)\n",
    "    total_consonants, max_consonants_sequence = consonants(prefix)\n",
    "    total_vowels, max_vowels_sequence = vowels(prefix)\n",
    "    return total_length, total_digits, max_numeric_sequence, total_consonants, max_consonants_sequence, total_vowels, max_vowels_sequence\n",
    "\n",
    "def vowels(prefix):\n",
    "    total_vowels = 0\n",
    "    vowels_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char == 'a' or char == 'e' or char == 'i' or char == 'o' or char == 'u':\n",
    "            total_vowels += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            vowels_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    vowels_sequence.append(current_sequence)\n",
    "    max_vowels_sequence = max(vowels_sequence)\n",
    "    return total_vowels, max_vowels_sequence\n",
    "\n",
    "def consonants(prefix):\n",
    "    total_consonants = 0\n",
    "    consonants_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char != 'a' and char != 'e' and char != 'i' and char != 'o' and char != 'u' and char != '-' and char.isdigit() == False:\n",
    "            total_consonants += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            consonants_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    consonants_sequence.append(current_sequence)\n",
    "    max_consonants_sequence = max(consonants_sequence)\n",
    "    return total_consonants, max_consonants_sequence\n",
    "\n",
    "def numeric(prefix):\n",
    "    total_digits = 0\n",
    "    numeric_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char.isdigit() == True:\n",
    "            total_digits += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            numeric_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    numeric_sequence.append(current_sequence)\n",
    "    max_numeric_sequence = max(numeric_sequence)\n",
    "    return total_digits, max_numeric_sequence\n",
    "            \n",
    "def find_prob(prefix, stats, fd):\n",
    "    tl, td, mns, tc, mcs, tv, mvs = handle_name(prefix)\n",
    "    try:\n",
    "        prob = stats[0][tl] * stats[1][td] * stats[2][mns] * stats[3][tc] * stats[4][mcs] * stats[5][tv] * stats[6][mvs]\n",
    "    except:\n",
    "        prob = 0\n",
    "        fd.write(prefix + \"\\n\")\n",
    "    return prob\n",
    "\n",
    "def apply_on_test_set(test_set, category, valid_stats, invalid_stats, fd):\n",
    "    misclassifications = 0\n",
    "    names_processed = 0\n",
    "    for prefix in test_set:\n",
    "        valid_prob = find_prob(prefix, valid_stats, fd)\n",
    "        invalid_prob = find_prob(prefix, invalid_stats, fd)\n",
    "        if valid_prob != 0 and invalid_prob != 0:\n",
    "            names_processed += 1\n",
    "            if category == \"valid\" and valid_prob < invalid_prob:\n",
    "                misclassifications += 1\n",
    "            elif category == \"invalid\" and valid_prob > invalid_prob:\n",
    "                misclassifications += 1\n",
    "    return misclassifications, names_processed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load valid names training set\n",
    "    valid_names_training = load_file(\"./valid_training.txt\")\n",
    "    # Load valid names test set\n",
    "    valid_names_test = load_file(\"./valid_test.txt\")\n",
    "    # Load invalid names training set\n",
    "    invalid_names_training = load_file(\"./invalid_training.txt\")\n",
    "    # Load invalid names test set\n",
    "    invalid_names_test = load_file(\"./invalid_test.txt\") \n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    valid_stats = calculate_probabilities(valid_names_training)\n",
    "    invalid_stats = calculate_probabilities(invalid_names_training)\n",
    "\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"Training time took: \", end_time-start_time)\n",
    "    print(\"Number of training examples valid - invalid and sum: \", len(valid_names_training),len(invalid_names_training),len(valid_names_training) + len(invalid_names_training))\n",
    "    \n",
    "    valid_misclassifications, valid_names_processed = apply_on_test_set(valid_names_test, \"valid\", valid_stats, invalid_stats, problematic1)\n",
    "    invalid_misclassifications, invalid_names_processed = apply_on_test_set(invalid_names_test, \"invalid\", valid_stats, invalid_stats, problematic2)\n",
    "\n",
    "    print(\"Valid names misclassified as invalid - Ratio: \", (valid_misclassifications / valid_names_processed) * 100)\n",
    "    print(\"Invalid names misclassified as valid - Ratio: \", (invalid_misclassifications / invalid_names_processed) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stochastic_Processes_&_Optimization_in_Machine_Learning_(Lab_7_DNS_Water_Torture).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
